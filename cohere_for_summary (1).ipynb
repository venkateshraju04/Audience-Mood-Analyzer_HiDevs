{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install praw transformers nltk emoji cohere dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Oe_vAj2AEuv",
        "outputId": "4793b1ef-6a7e-4c4b-f6bd-cea759a6901a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.11/dist-packages (0.9.9)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.11.1)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.11.4)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20250515)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.13.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxa3s_iikerO",
        "outputId": "aff8f0a8-e90f-49f0-a269-125b58cdfdab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.8)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xgnzDFBj_6Dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "a74f7004-6b8e-44d7-8550-073be0f26d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import praw, re, json, emoji, cohere\n",
        "import streamlit as st\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import pipeline\n",
        "import nltk\n",
        "import dotenv\n",
        "\n",
        "\n",
        "#Reddit API\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"XYdZOfOt56Y_c6VgzY9Lhw\",\n",
        "    client_secret=\"6M3LpUJ4fWS_a9rjV5OgOjLRnBGBtg\",\n",
        "    user_agent=\"sentiment-analyzer by u/potential_problem\"\n",
        ")\n",
        "\n",
        "# Cohere API\n",
        "co = cohere.Client(\"HIPZcL01IEuowrHCCluAD6VEEWmlDmmDcpFCiARj\")\n",
        "\n",
        "def extract_comments_from_post(post_url):\n",
        "    submission = reddit.submission(url=post_url)\n",
        "    submission.comments.replace_more(limit=0)\n",
        "    comments_data = []\n",
        "    for comment in submission.comments.list():\n",
        "        comments_data.append({\n",
        "            \"comment_id\": comment.id,\n",
        "            \"author\": str(comment.author),\n",
        "            \"body\": comment.body,\n",
        "            \"score\": comment.score,\n",
        "            \"created_utc\": comment.created_utc\n",
        "        })\n",
        "    return comments_data\n",
        "\n",
        "def extract_emojis(text):\n",
        "    return ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    return \" \".join([t for t in tokens if t not in stopwords.words(\"english\")])\n",
        "\n",
        "# Sentiment model\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"NEGATIVE\",\n",
        "    \"LABEL_1\": \"NEUTRAL\",\n",
        "    \"LABEL_2\": \"POSITIVE\"\n",
        "}\n",
        "\n",
        "def add_sentiment_to_comments(comments):\n",
        "    for c in comments:\n",
        "        try:\n",
        "            c[\"cleaned\"] = clean_text(c[\"body\"])\n",
        "            result = sentiment_pipeline(c[\"cleaned\"][:512])[0]\n",
        "            c[\"sentiment\"] = label_map.get(result[\"label\"], \"UNKNOWN\")\n",
        "            c[\"sentiment_score\"] = round(result[\"score\"], 4)\n",
        "        except:\n",
        "            c[\"sentiment\"] = \"ERROR\"\n",
        "            c[\"sentiment_score\"] = 0.0\n",
        "    return comments\n",
        "\n",
        "def calculate_sentiment_percentages(comments):\n",
        "    sentiment_counts = Counter([c[\"sentiment\"] for c in comments])\n",
        "    total = sum(sentiment_counts.values())\n",
        "    return {k: round((v / total) * 100, 2) for k, v in sentiment_counts.items()}\n",
        "\n",
        "def summarize_comments_with_cohere(comments, sentiment_type=\"POSITIVE\"):\n",
        "    text_block = \" \".join([c[\"cleaned\"] for c in comments if c[\"sentiment\"] == sentiment_type])\n",
        "    if len(text_block.strip()) < 250:\n",
        "        # Return raw or a fallback message if too short\n",
        "        return f\"Not enough {sentiment_type.lower()} comments to summarize properly.\"\n",
        "\n",
        "    response = co.summarize(\n",
        "        text=text_block[:4000],  # limit to 4k chars max\n",
        "        model=\"summarize-xlarge\",\n",
        "        length=\"medium\",\n",
        "        format=\"paragraph\",\n",
        "        temperature=0.3,\n",
        "        extractiveness=\"medium\"\n",
        "    )\n",
        "    return response.summary\n",
        "\n",
        "\n",
        "st.title(\"üìä Reddit Post Sentiment Analyzer\")\n",
        "\n",
        "post_url = st.text_input(\"Enter Reddit Post URL:\")\n",
        "if st.button(\"Analyze\") and post_url:\n",
        "    with st.spinner(\"Extracting and analyzing comments...\"):\n",
        "        comments = extract_comments_from_post(post_url)\n",
        "        comments = add_sentiment_to_comments(comments)\n",
        "\n",
        "        with open(\"reddit_sentiment_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "          json.dump(comments, f, indent=2)\n",
        "        percents = calculate_sentiment_percentages(comments)\n",
        "        pos_summary = summarize_comments_with_cohere(comments, \"POSITIVE\")\n",
        "        neg_summary = summarize_comments_with_cohere(comments, \"NEGATIVE\")\n",
        "\n",
        "    st.subheader(\"Sentiment Breakdown:\")\n",
        "    st.json(percents)\n",
        "\n",
        "    st.subheader(\"üü¢ Positive Summary:\")\n",
        "    st.write(pos_summary)\n",
        "\n",
        "    st.subheader(\"üî¥ Negative Summary:\")\n",
        "    st.write(neg_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Kill previous processes\n",
        "!pkill streamlit\n",
        "ngrok.set_auth_token(\"2xadYlBxzGDr8KGuiMXfYIiL56Z_6ZKQM72Yvn9iPRceBnkvY\")\n",
        "# Open tunnel\n",
        "public_url = ngrok.connect(8501, \"http\")  # Correct call: (port, \"http\")\n",
        "\n",
        "print(f\"üåê Public URL: {public_url}\")\n",
        "\n",
        "# Wait for ngrok to set up\n",
        "time.sleep(3)\n",
        "\n",
        "# Launch Streamlit\n",
        "!streamlit run app.py &>/content/log.txt &\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic3SxfYAj9NF",
        "outputId": "b7e0b111-7899-4d04-9099-f6060aec7c69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Public URL: NgrokTunnel: \"https://cf7d-34-125-152-230.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-05-25T13:48:35+0000 lvl=warn msg=\"failed to open private leg\" id=29c13fcd74d2 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-05-25T13:48:35+0000 lvl=warn msg=\"failed to open private leg\" id=ebfbf54831b8 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-05-25T13:48:37+0000 lvl=warn msg=\"failed to open private leg\" id=2b2845594435 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-05-25T13:48:37+0000 lvl=warn msg=\"failed to open private leg\" id=e33a57739ba4 privaddr=localhost:8501 err=\"dial tcp 127.0.0.1:8501: connect: connection refused\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_url=\"https://www.reddit.com/r/oneplus/comments/1kk7s4u/bought_op13_after_watching_100s_of_videos_3/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button\"\n",
        "analyze_reddit_post(post_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0v08z65C_0U",
        "outputId": "b9c89c52-758f-4d65-bcef-04c9aa811448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Extracting comments...\n",
            "üîç Analyzing sentiment...\n",
            "\n",
            "üìä Sentiment Percentages:\n",
            "- POSITIVE: 33.33%\n",
            "- NEUTRAL: 55.25%\n",
            "- NEGATIVE: 11.42%\n",
            "\n",
            "üü¢ Summary of Positive Comments:\n",
            "The user is enjoying their new OnePlus 13. They have watched many videos and have decided to stick with this phone instead of waiting for the next flagship. They mention that the phone is well-balanced, has good battery life, and has a smooth operating system. They also appreciate the phone's design, cameras, and speakers. They also talk about the competition and their own preferences. They also mention that they have ordered an OP12 as well, and are also considering other Chinese phones like Oppo and Poco.\n",
            "\n",
            "üî¥ Summary of Negative Comments:\n",
            "User is considering buying the OnePlus 13 and is looking for information regarding the phone's specs, repairability and general performance. They are coming from an OnePlus 6T and are concerned about battery life and video quality. User is also frustrated with their current phone, a Google Pixel 8, which has a white horizontal line on the screen and poor customer service. They are also considering the iPhone 16 Pro and a MacBook. User expresses confusion about whether to choose the OP13 or the iPhone, and notes general frustration with bugs and issues with both brands.\n"
          ]
        }
      ]
    }
  ]
}